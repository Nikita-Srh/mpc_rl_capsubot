{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example of model usage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#%matplotlib\n",
    "from envs.CapsubotEnv import CapsubotEnv\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# pip install stable-baselines3[extra]\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common.cmd_util import make_vec_env\n",
    "\n",
    "try:\n",
    "    env.close()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "env = CapsubotEnv(force=\"step\")\n",
    "check_env(env)\n",
    "\n",
    "\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(env.action_space.sample())\n",
    "dt = env.dt\n",
    "\n",
    "env = make_vec_env(lambda: env, n_envs=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Box(-10.0, 10.0, (4,), float32)\n",
      "Discrete(2)\n",
      "1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/xfirefly/.local/lib/python3.8/site-packages/stable_baselines3/common/cmd_util.py:5: FutureWarning: Module ``common.cmd_util`` has been renamed to ``common.env_util`` and will be removed in the future.\n",
      "  warnings.warn(\n",
      "/home/xfirefly/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Train the agent\n",
    "ts_num = 10./dt\n",
    "print(ts_num)\n",
    "model = PPO('MlpPolicy', env, verbose=1).learn(ts_num)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200000.0\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1531 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1105         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014264906 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.693       |\n",
      "|    explained_variance   | 0.00486      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.35         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 955           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039096046 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.692        |\n",
      "|    explained_variance   | 0.526         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.26          |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000224     |\n",
      "|    value_loss           | 10.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 927          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010881306 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.693       |\n",
      "|    explained_variance   | 0.807        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00057     |\n",
      "|    value_loss           | 7.04         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 945         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014979806 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.16        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    value_loss           | 6.84        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 927        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01077917 |\n",
      "|    clip_fraction        | 0.0268     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.646     |\n",
      "|    explained_variance   | 0.881      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.96       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.000454  |\n",
      "|    value_loss           | 5.42       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 917         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009936139 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 6.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 902         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006922263 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    value_loss           | 5.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 904         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007274989 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.438      |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.486       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    value_loss           | 2.09        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 946          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067808973 |\n",
      "|    clip_fraction        | 0.0807       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.363       |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.388        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00855     |\n",
      "|    value_loss           | 1.75         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 973          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024397143 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.303       |\n",
      "|    explained_variance   | 0.828        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.03         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    value_loss           | 5.56         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1007         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019612468 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.276       |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.26         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000188    |\n",
      "|    value_loss           | 5.64         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1030         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017600269 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.23        |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2            |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000624    |\n",
      "|    value_loss           | 5.38         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1057         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009918456 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.201       |\n",
      "|    explained_variance   | 0.851        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.43         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 8.03         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1077         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011258412 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.159       |\n",
      "|    explained_variance   | 0.851        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.49         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    value_loss           | 8.62         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.905145e-05 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.135       |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.3          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | 1.99e-05     |\n",
      "|    value_loss           | 8.95         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1112          |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 31            |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079551584 |\n",
      "|    clip_fraction        | 0.0207        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.125        |\n",
      "|    explained_variance   | 0.901         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.26          |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.00208      |\n",
      "|    value_loss           | 3.22          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1111         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011062203 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0823       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 0.235        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1112         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017206729 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0862      |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0545       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 0.216        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1090         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010801458 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0601      |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0271       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 0.122        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1099          |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 39            |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096665765 |\n",
      "|    clip_fraction        | 0.0083        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0399       |\n",
      "|    explained_variance   | 0.932         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0275        |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.00252      |\n",
      "|    value_loss           | 0.0681        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1111          |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 40            |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026475827 |\n",
      "|    clip_fraction        | 0.00859       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.03         |\n",
      "|    explained_variance   | 0.891         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0137        |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -0.00243      |\n",
      "|    value_loss           | 0.0601        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1123         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015569761 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.017       |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.013        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    value_loss           | 0.0417       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1134         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.356241e-05 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0119      |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00908      |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000487    |\n",
      "|    value_loss           | 0.0319       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1145         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009275543 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00456     |\n",
      "|    explained_variance   | 0.868        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0101       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000973    |\n",
      "|    value_loss           | 0.0253       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1134      |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00421  |\n",
      "|    explained_variance   | 0.909     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00779   |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -1.28e-07 |\n",
      "|    value_loss           | 0.022     |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1137          |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 48            |\n",
      "|    total_timesteps      | 55296         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020148739 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00208      |\n",
      "|    explained_variance   | 0.884         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00732       |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -0.00021      |\n",
      "|    value_loss           | 0.02          |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1130      |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00166  |\n",
      "|    explained_variance   | 0.874     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00716   |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -5.02e-09 |\n",
      "|    value_loss           | 0.0168    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 1140     |\n",
      "|    iterations           | 29       |\n",
      "|    time_elapsed         | 52       |\n",
      "|    total_timesteps      | 59392    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00166 |\n",
      "|    explained_variance   | 0.868    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00639  |\n",
      "|    n_updates            | 280      |\n",
      "|    policy_gradient_loss | -6e-09   |\n",
      "|    value_loss           | 0.014    |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1149          |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 53            |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2027136e-05 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00122      |\n",
      "|    explained_variance   | 0.882         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00529       |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.000107     |\n",
      "|    value_loss           | 0.011         |\n",
      "-------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 1159     |\n",
      "|    iterations           | 31       |\n",
      "|    time_elapsed         | 54       |\n",
      "|    total_timesteps      | 63488    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00118 |\n",
      "|    explained_variance   | 0.91     |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00284  |\n",
      "|    n_updates            | 300      |\n",
      "|    policy_gradient_loss | 7.1e-09  |\n",
      "|    value_loss           | 0.00714  |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1161          |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 56            |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032903027 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000372     |\n",
      "|    explained_variance   | 0.933         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00288       |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.000367     |\n",
      "|    value_loss           | 0.00534       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1149      |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 58        |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000319 |\n",
      "|    explained_variance   | 0.964     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000769  |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | 1.51e-08  |\n",
      "|    value_loss           | 0.00261   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1148      |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 60        |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000319 |\n",
      "|    explained_variance   | 0.983     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000502  |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -2.07e-08 |\n",
      "|    value_loss           | 0.00135   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1146      |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000319 |\n",
      "|    explained_variance   | 0.994     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000109  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -3.55e-08 |\n",
      "|    value_loss           | 0.000542  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1149      |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000319 |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.48e-05  |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | 2.43e-09  |\n",
      "|    value_loss           | 0.000182  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1134      |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000318 |\n",
      "|    explained_variance   | 0.999     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.96e-06  |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -2.18e-09 |\n",
      "|    value_loss           | 7.25e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1127      |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000318 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.37e-05  |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | -9.1e-08  |\n",
      "|    value_loss           | 6.98e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1133      |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 70        |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000318 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7e-06     |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -1.03e-07 |\n",
      "|    value_loss           | 9.68e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1140      |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000318 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.33e-06  |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | 3.77e-08  |\n",
      "|    value_loss           | 9.41e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1147      |\n",
      "|    iterations           | 41        |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 83968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000317 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.08e-06  |\n",
      "|    n_updates            | 400       |\n",
      "|    policy_gradient_loss | -1.33e-07 |\n",
      "|    value_loss           | 2.04e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1153      |\n",
      "|    iterations           | 42        |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 86016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000317 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -1.9e-06  |\n",
      "|    n_updates            | 410       |\n",
      "|    policy_gradient_loss | 4.26e-07  |\n",
      "|    value_loss           | 1.59e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1159      |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 75        |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000316 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.03e-06  |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | 5.65e-08  |\n",
      "|    value_loss           | 2.42e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1165      |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 90112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000315 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.05e-06  |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | 7.54e-07  |\n",
      "|    value_loss           | 5.29e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1171      |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000316 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.67e-06  |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | 7.63e-08  |\n",
      "|    value_loss           | 9.32e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1168      |\n",
      "|    iterations           | 46        |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 94208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000316 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -8.71e-06 |\n",
      "|    n_updates            | 450       |\n",
      "|    policy_gradient_loss | 6.6e-08   |\n",
      "|    value_loss           | 0.000111  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1152      |\n",
      "|    iterations           | 47        |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 96256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000314 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.43e-06  |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | 2.76e-08  |\n",
      "|    value_loss           | 3.96e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1155      |\n",
      "|    iterations           | 48        |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 98304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000314 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -1.58e-05 |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | 4.51e-08  |\n",
      "|    value_loss           | 1.54e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1161      |\n",
      "|    iterations           | 49        |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 100352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000314 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.76e-05  |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | -1.23e-07 |\n",
      "|    value_loss           | 0.000876  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1162      |\n",
      "|    iterations           | 50        |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 102400    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000313 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.55e-07  |\n",
      "|    n_updates            | 490       |\n",
      "|    policy_gradient_loss | -5.76e-08 |\n",
      "|    value_loss           | 4.33e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1162      |\n",
      "|    iterations           | 51        |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 104448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000311 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -1.67e-06 |\n",
      "|    n_updates            | 500       |\n",
      "|    policy_gradient_loss | 1.3e-07   |\n",
      "|    value_loss           | 2.41e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1160      |\n",
      "|    iterations           | 52        |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 106496    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00031  |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -3.22e-08 |\n",
      "|    n_updates            | 510       |\n",
      "|    policy_gradient_loss | -1.98e-06 |\n",
      "|    value_loss           | 2.37e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1163      |\n",
      "|    iterations           | 53        |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 108544    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000309 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.25e-07  |\n",
      "|    n_updates            | 520       |\n",
      "|    policy_gradient_loss | 1.51e-06  |\n",
      "|    value_loss           | 2.6e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1165      |\n",
      "|    iterations           | 54        |\n",
      "|    time_elapsed         | 94        |\n",
      "|    total_timesteps      | 110592    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000309 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.98e-06  |\n",
      "|    n_updates            | 530       |\n",
      "|    policy_gradient_loss | 3.27e-07  |\n",
      "|    value_loss           | 9.04e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1167      |\n",
      "|    iterations           | 55        |\n",
      "|    time_elapsed         | 96        |\n",
      "|    total_timesteps      | 112640    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000306 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.55e-07  |\n",
      "|    n_updates            | 540       |\n",
      "|    policy_gradient_loss | -9.85e-08 |\n",
      "|    value_loss           | 1.34e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1170      |\n",
      "|    iterations           | 56        |\n",
      "|    time_elapsed         | 98        |\n",
      "|    total_timesteps      | 114688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000304 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.69e-06  |\n",
      "|    n_updates            | 550       |\n",
      "|    policy_gradient_loss | 9.53e-09  |\n",
      "|    value_loss           | 1.38e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1168      |\n",
      "|    iterations           | 57        |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 116736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000308 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.35e-06  |\n",
      "|    n_updates            | 560       |\n",
      "|    policy_gradient_loss | -9.59e-07 |\n",
      "|    value_loss           | 1.37e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1170      |\n",
      "|    iterations           | 58        |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 118784    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000307 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.41e-07  |\n",
      "|    n_updates            | 570       |\n",
      "|    policy_gradient_loss | 3.06e-07  |\n",
      "|    value_loss           | 0.00039   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1172      |\n",
      "|    iterations           | 59        |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 120832    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0003   |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -1.99e-06 |\n",
      "|    n_updates            | 580       |\n",
      "|    policy_gradient_loss | -2.43e-08 |\n",
      "|    value_loss           | 1.57e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1175      |\n",
      "|    iterations           | 60        |\n",
      "|    time_elapsed         | 104       |\n",
      "|    total_timesteps      | 122880    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000296 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.3e-06   |\n",
      "|    n_updates            | 590       |\n",
      "|    policy_gradient_loss | -5.66e-07 |\n",
      "|    value_loss           | 9.13e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1178      |\n",
      "|    iterations           | 61        |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 124928    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000289 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.95e-08  |\n",
      "|    n_updates            | 600       |\n",
      "|    policy_gradient_loss | 8.12e-08  |\n",
      "|    value_loss           | 1.28e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1179      |\n",
      "|    iterations           | 62        |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 126976    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000288 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -3.04e-08 |\n",
      "|    n_updates            | 610       |\n",
      "|    policy_gradient_loss | -1.82e-07 |\n",
      "|    value_loss           | 1.17e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1180      |\n",
      "|    iterations           | 63        |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 129024    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000288 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -5.13e-08 |\n",
      "|    n_updates            | 620       |\n",
      "|    policy_gradient_loss | 1.63e-08  |\n",
      "|    value_loss           | 1.36e-05  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1181          |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 110           |\n",
      "|    total_timesteps      | 131072        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050711515 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.52e-05     |\n",
      "|    explained_variance   | 0.99          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000356      |\n",
      "|    n_updates            | 630           |\n",
      "|    policy_gradient_loss | -0.000575     |\n",
      "|    value_loss           | 0.00135       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1181      |\n",
      "|    iterations           | 65        |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 133120    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 0.99      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000142  |\n",
      "|    n_updates            | 640       |\n",
      "|    policy_gradient_loss | 7.48e-09  |\n",
      "|    value_loss           | 0.000465  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1182      |\n",
      "|    iterations           | 66        |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 135168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 0.996     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.88e-05  |\n",
      "|    n_updates            | 650       |\n",
      "|    policy_gradient_loss | 2.3e-10   |\n",
      "|    value_loss           | 0.000344  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1184      |\n",
      "|    iterations           | 67        |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 137216    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.87e-05  |\n",
      "|    n_updates            | 660       |\n",
      "|    policy_gradient_loss | -1.14e-09 |\n",
      "|    value_loss           | 0.000109  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1185      |\n",
      "|    iterations           | 68        |\n",
      "|    time_elapsed         | 117       |\n",
      "|    total_timesteps      | 139264    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.16e-05  |\n",
      "|    n_updates            | 670       |\n",
      "|    policy_gradient_loss | 1.58e-09  |\n",
      "|    value_loss           | 3.19e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1187      |\n",
      "|    iterations           | 69        |\n",
      "|    time_elapsed         | 119       |\n",
      "|    total_timesteps      | 141312    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.73e-06  |\n",
      "|    n_updates            | 680       |\n",
      "|    policy_gradient_loss | -1.51e-09 |\n",
      "|    value_loss           | 1.07e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1188      |\n",
      "|    iterations           | 70        |\n",
      "|    time_elapsed         | 120       |\n",
      "|    total_timesteps      | 143360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.99e-06  |\n",
      "|    n_updates            | 690       |\n",
      "|    policy_gradient_loss | -3.87e-10 |\n",
      "|    value_loss           | 6.08e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1190      |\n",
      "|    iterations           | 71        |\n",
      "|    time_elapsed         | 122       |\n",
      "|    total_timesteps      | 145408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.61e-06  |\n",
      "|    n_updates            | 700       |\n",
      "|    policy_gradient_loss | -8.8e-09  |\n",
      "|    value_loss           | 2.75e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1191      |\n",
      "|    iterations           | 72        |\n",
      "|    time_elapsed         | 123       |\n",
      "|    total_timesteps      | 147456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.5e-07   |\n",
      "|    n_updates            | 710       |\n",
      "|    policy_gradient_loss | 5.08e-09  |\n",
      "|    value_loss           | 1.31e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1194      |\n",
      "|    iterations           | 73        |\n",
      "|    time_elapsed         | 125       |\n",
      "|    total_timesteps      | 149504    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.35e-07  |\n",
      "|    n_updates            | 720       |\n",
      "|    policy_gradient_loss | 2.15e-09  |\n",
      "|    value_loss           | 1.27e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1197      |\n",
      "|    iterations           | 74        |\n",
      "|    time_elapsed         | 126       |\n",
      "|    total_timesteps      | 151552    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.83e-07  |\n",
      "|    n_updates            | 730       |\n",
      "|    policy_gradient_loss | 2.48e-08  |\n",
      "|    value_loss           | 1.46e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1197      |\n",
      "|    iterations           | 75        |\n",
      "|    time_elapsed         | 128       |\n",
      "|    total_timesteps      | 153600    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.95e-06  |\n",
      "|    n_updates            | 740       |\n",
      "|    policy_gradient_loss | -1.65e-08 |\n",
      "|    value_loss           | 1.37e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1199      |\n",
      "|    iterations           | 76        |\n",
      "|    time_elapsed         | 129       |\n",
      "|    total_timesteps      | 155648    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.99e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.03e-06  |\n",
      "|    n_updates            | 750       |\n",
      "|    policy_gradient_loss | -6.13e-08 |\n",
      "|    value_loss           | 1.24e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1202      |\n",
      "|    iterations           | 77        |\n",
      "|    time_elapsed         | 131       |\n",
      "|    total_timesteps      | 157696    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.99e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.39e-06  |\n",
      "|    n_updates            | 760       |\n",
      "|    policy_gradient_loss | -2.45e-08 |\n",
      "|    value_loss           | 1.62e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1205      |\n",
      "|    iterations           | 78        |\n",
      "|    time_elapsed         | 132       |\n",
      "|    total_timesteps      | 159744    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.99e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.04e-06  |\n",
      "|    n_updates            | 770       |\n",
      "|    policy_gradient_loss | 3.43e-08  |\n",
      "|    value_loss           | 1.33e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1207      |\n",
      "|    iterations           | 79        |\n",
      "|    time_elapsed         | 133       |\n",
      "|    total_timesteps      | 161792    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.99e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.21e-05  |\n",
      "|    n_updates            | 780       |\n",
      "|    policy_gradient_loss | 9.99e-08  |\n",
      "|    value_loss           | 1.33e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1210      |\n",
      "|    iterations           | 80        |\n",
      "|    time_elapsed         | 135       |\n",
      "|    total_timesteps      | 163840    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.99e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.64e-08  |\n",
      "|    n_updates            | 790       |\n",
      "|    policy_gradient_loss | -1.12e-08 |\n",
      "|    value_loss           | 1.2e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1212      |\n",
      "|    iterations           | 81        |\n",
      "|    time_elapsed         | 136       |\n",
      "|    total_timesteps      | 165888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.99e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.92e-06  |\n",
      "|    n_updates            | 800       |\n",
      "|    policy_gradient_loss | -2.97e-09 |\n",
      "|    value_loss           | 1.31e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1215      |\n",
      "|    iterations           | 82        |\n",
      "|    time_elapsed         | 138       |\n",
      "|    total_timesteps      | 167936    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.99e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.3e-07   |\n",
      "|    n_updates            | 810       |\n",
      "|    policy_gradient_loss | -1.02e-07 |\n",
      "|    value_loss           | 1.39e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1217      |\n",
      "|    iterations           | 83        |\n",
      "|    time_elapsed         | 139       |\n",
      "|    total_timesteps      | 169984    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.99e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.47e-07  |\n",
      "|    n_updates            | 820       |\n",
      "|    policy_gradient_loss | -1.07e-07 |\n",
      "|    value_loss           | 0.00072   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1219      |\n",
      "|    iterations           | 84        |\n",
      "|    time_elapsed         | 141       |\n",
      "|    total_timesteps      | 172032    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.99e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.63e-06  |\n",
      "|    n_updates            | 830       |\n",
      "|    policy_gradient_loss | -7.98e-07 |\n",
      "|    value_loss           | 4.22e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1221      |\n",
      "|    iterations           | 85        |\n",
      "|    time_elapsed         | 142       |\n",
      "|    total_timesteps      | 174080    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.13e-06  |\n",
      "|    n_updates            | 840       |\n",
      "|    policy_gradient_loss | -4.5e-08  |\n",
      "|    value_loss           | 1.3e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1224      |\n",
      "|    iterations           | 86        |\n",
      "|    time_elapsed         | 143       |\n",
      "|    total_timesteps      | 176128    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.98e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.72e-07  |\n",
      "|    n_updates            | 850       |\n",
      "|    policy_gradient_loss | 4.85e-08  |\n",
      "|    value_loss           | 1.38e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1223      |\n",
      "|    iterations           | 87        |\n",
      "|    time_elapsed         | 145       |\n",
      "|    total_timesteps      | 178176    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.99e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.31e-06  |\n",
      "|    n_updates            | 860       |\n",
      "|    policy_gradient_loss | 1.13e-08  |\n",
      "|    value_loss           | 1.19e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1223      |\n",
      "|    iterations           | 88        |\n",
      "|    time_elapsed         | 147       |\n",
      "|    total_timesteps      | 180224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5e-05    |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -8.27e-07 |\n",
      "|    n_updates            | 870       |\n",
      "|    policy_gradient_loss | 2.02e-07  |\n",
      "|    value_loss           | 0.000131  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 1223     |\n",
      "|    iterations           | 89       |\n",
      "|    time_elapsed         | 148      |\n",
      "|    total_timesteps      | 182272   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -5e-05   |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 1.13e-06 |\n",
      "|    n_updates            | 880      |\n",
      "|    policy_gradient_loss | 5.34e-07 |\n",
      "|    value_loss           | 8.31e-06 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1224      |\n",
      "|    iterations           | 90        |\n",
      "|    time_elapsed         | 150       |\n",
      "|    total_timesteps      | 184320    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5e-05    |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -4.83e-06 |\n",
      "|    n_updates            | 890       |\n",
      "|    policy_gradient_loss | 1.84e-07  |\n",
      "|    value_loss           | 1.3e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 1222     |\n",
      "|    iterations           | 91       |\n",
      "|    time_elapsed         | 152      |\n",
      "|    total_timesteps      | 186368   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -5e-05   |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 3.25e-05 |\n",
      "|    n_updates            | 900      |\n",
      "|    policy_gradient_loss | 2.7e-06  |\n",
      "|    value_loss           | 1.47e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1222      |\n",
      "|    iterations           | 92        |\n",
      "|    time_elapsed         | 154       |\n",
      "|    total_timesteps      | 188416    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.01e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000244  |\n",
      "|    n_updates            | 910       |\n",
      "|    policy_gradient_loss | 1.09e-07  |\n",
      "|    value_loss           | 0.000835  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1223      |\n",
      "|    iterations           | 93        |\n",
      "|    time_elapsed         | 155       |\n",
      "|    total_timesteps      | 190464    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.02e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.77e-07  |\n",
      "|    n_updates            | 920       |\n",
      "|    policy_gradient_loss | -1.53e-08 |\n",
      "|    value_loss           | 1.13e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1225      |\n",
      "|    iterations           | 94        |\n",
      "|    time_elapsed         | 157       |\n",
      "|    total_timesteps      | 192512    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.02e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -5.46e-06 |\n",
      "|    n_updates            | 930       |\n",
      "|    policy_gradient_loss | -1.98e-06 |\n",
      "|    value_loss           | 1.6e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1224      |\n",
      "|    iterations           | 95        |\n",
      "|    time_elapsed         | 158       |\n",
      "|    total_timesteps      | 194560    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.02e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.92e-06  |\n",
      "|    n_updates            | 940       |\n",
      "|    policy_gradient_loss | -1.26e-06 |\n",
      "|    value_loss           | 1.72e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1223      |\n",
      "|    iterations           | 96        |\n",
      "|    time_elapsed         | 160       |\n",
      "|    total_timesteps      | 196608    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.01e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.86e-06  |\n",
      "|    n_updates            | 950       |\n",
      "|    policy_gradient_loss | 1.93e-08  |\n",
      "|    value_loss           | 2.75e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1222      |\n",
      "|    iterations           | 97        |\n",
      "|    time_elapsed         | 162       |\n",
      "|    total_timesteps      | 198656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.01e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00161   |\n",
      "|    n_updates            | 960       |\n",
      "|    policy_gradient_loss | -7.23e-07 |\n",
      "|    value_loss           | 0.00236   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1216      |\n",
      "|    iterations           | 98        |\n",
      "|    time_elapsed         | 164       |\n",
      "|    total_timesteps      | 200704    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.01e-05 |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.17e-06  |\n",
      "|    n_updates            | 970       |\n",
      "|    policy_gradient_loss | -7.36e-08 |\n",
      "|    value_loss           | 1.05e-05  |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Test the trained agent\n",
    "obs = env.reset()\n",
    "n_steps = int(5.0/dt)\n",
    "t = 0.0\n",
    "states = [obs[0]]\n",
    "actions = [0]\n",
    "ts = [t]\n",
    "for step in range(n_steps):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    t += dt\n",
    "    states.append(obs[0])\n",
    "    actions.append(action[0])\n",
    "    ts.append(t)\n",
    "    if t % 0.005 <= dt:\n",
    "        print(\"Step {}\".format(step + 1))\n",
    "        print(\"Action: \", action)\n",
    "        print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
    "        env.render()\n",
    "    if done:\n",
    "        # Note that the VecEnv resets automatically\n",
    "        # when a done signal is encountered\n",
    "        print(\"Goal reached!\", \"reward=\", reward)\n",
    "        break\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Step 1\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 1000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 1100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 1200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 1300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 1400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 1501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 1601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 1701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 1801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 1901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 2001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 2101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 2201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 2301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 2401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 2501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 2601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 2701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 2801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 2901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 3001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 3101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 3201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 3301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 3401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 3501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 3601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 3701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 3801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 3901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 4001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 4101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 4201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 4301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 4401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 4501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 4601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 4701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 4801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 4901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 5001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 5101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 5201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 5301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 5401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 5501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 5601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 5701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 5801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 5901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 6001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 6101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 6201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 6301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 6401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 6501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 6601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 6701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 6801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 6901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 7001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 7101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 7201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 7301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 7401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 7501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 7601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 7701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 7801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 7901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 8001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 8101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 8201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 8301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 8401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 8501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 8601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 8701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 8801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 8901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 9001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 9101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 9201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 9301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 9401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 9501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 9601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 9701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 9801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 9901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 10001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 10101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 10201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 10301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 10401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 10501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 10601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 10701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 10801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 10901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 11001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 11101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 11201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 11301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 11401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 11501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 11601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 11701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 11801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 11901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 12001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 12101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 12201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 12301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 12401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 12501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 12601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 12701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 12801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 12901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 13001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 13101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 13201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 13301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 13401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 13501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 13601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 13701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 13801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 13901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 14001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 14101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 14201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 14301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 14401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 14501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 14601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 14701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 14801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 14901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 15001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 15101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 15201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 15301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 15401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 15501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 15601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 15701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 15801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 15901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 16001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 16101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 16201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 16301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 16401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 16501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 16601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 16701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 16801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 16901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 17001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 17101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 17201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 17301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 17401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 17501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 17601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 17701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 17801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 17901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 18001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 18101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 18201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 18301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 18401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 18501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 18601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 18701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 18801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 18901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 19001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 19101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 19201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 19301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 19401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 19501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 19601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 19701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 19801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 19901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 20001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 20101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 20201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 20301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 20401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 20501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 20601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 20701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 20801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 20901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 21000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 21100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 21200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 21300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 21400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 21500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 21600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 21700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 21800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 21900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 22000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 22100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 22200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 22300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 22400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 22500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 22600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 22700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 22800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 22900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 23000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 23100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 23200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 23300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 23400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 23500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 23600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 23700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 23800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 23900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 24000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 24100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 24200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 24300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 24400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 24500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 24600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 24700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 24800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 24900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 25000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 25100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 25200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 25300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 25400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 25500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 25600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 25700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 25800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 25900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 26000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 26100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 26200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 26300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 26400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 26500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 26600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 26700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 26800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 26900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 27000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 27100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 27200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 27300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 27400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 27500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 27600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 27700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 27800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 27900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 28000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 28100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 28200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 28300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 28400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 28500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 28600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 28700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 28800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 28900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 29000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 29100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 29200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 29300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 29400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 29500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 29600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 29700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 29800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 29900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 30000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 30100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 30200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 30300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 30400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 30500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 30600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 30700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 30800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 30900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 31000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 31100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 31200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 31300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 31400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 31500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 31600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 31700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 31800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 31900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 32000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 32100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 32200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 32300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 32400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 32500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 32600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 32700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 32800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 32900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 33000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 33100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 33200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 33300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 33400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 33500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 33600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 33700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 33800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 33900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 34000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 34100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 34200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 34300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 34400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 34500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 34600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 34700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 34800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 34900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 35000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 35100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 35200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 35300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 35400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 35500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 35600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 35700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 35800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 35900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 36000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 36100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 36200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 36300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 36400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 36500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 36600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 36700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 36800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 36900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 37000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 37100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 37200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 37300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 37400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 37500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 37600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 37700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 37800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 37900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 38000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 38100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 38200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 38300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 38400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 38500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 38600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 38700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 38800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 38900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 39000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 39100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 39200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 39300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 39400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 39500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 39600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 39700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 39800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 39900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 40000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 40100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 40200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 40300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 40400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 40500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 40600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 40700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 40800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 40900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 41000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 41100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 41200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 41300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 41400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 41500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 41600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 41700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 41800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 41900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 42000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 42100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 42200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 42300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 42400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 42500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 42600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 42700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 42800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 42900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 43000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 43100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 43200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 43300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 43400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 43500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 43600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 43700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 43800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 43900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 44000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 44100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 44200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 44300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 44400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 44500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 44600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 44700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 44800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 44900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 45000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 45100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 45200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 45300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 45400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 45500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 45600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 45700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 45800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 45900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 46000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 46100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 46200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 46300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 46400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 46500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 46600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 46700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 46800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 46900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 47000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 47100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 47200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 47300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 47400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 47500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 47600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 47700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 47800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 47900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 48000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 48100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 48200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 48300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 48400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 48500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 48600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 48700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 48800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 48900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 49000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 49100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 49200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 49300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 49400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 49500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 49600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 49700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 49800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 49900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 50000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 50100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 50200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 50300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 50400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 50500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 50600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 50700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 50800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 50900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 51000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 51100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 51200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 51300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 51400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 51500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 51600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 51700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 51800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 51900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 52000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 52100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 52200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 52300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 52400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 52500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 52600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 52700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 52800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 52900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 53000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 53100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 53200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 53300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 53400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 53500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 53600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 53700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 53800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 53900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 54000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 54100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 54200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 54300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 54400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 54500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 54600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 54700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 54800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 54900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 55000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 55100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 55200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 55300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 55400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 55500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 55600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 55700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 55800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 55900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 56000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 56100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 56200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 56300\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 56400\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 56500\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 56600\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 56700\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 56800\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 56900\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 57000\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 57100\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 57200\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 57301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 57401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 57501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 57601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 57701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 57801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 57901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 58001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 58101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 58201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 58301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 58401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 58501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 58601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 58701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 58801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 58901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 59001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 59101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 59201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 59301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 59401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 59501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 59601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 59701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 59801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 59901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 60001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 60101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 60201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 60301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 60401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 60501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 60601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 60701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 60801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 60901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 61001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 61101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 61201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 61301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 61401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 61501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 61601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 61701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 61801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 61901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 62001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 62101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 62201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 62301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 62401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 62501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 62601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 62701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 62801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 62901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 63001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 63101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 63201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 63301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 63401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 63501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 63601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 63701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 63801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 63901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 64001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 64101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 64201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 64301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 64401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 64501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 64601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 64701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 64801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 64901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 65001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 65101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 65201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 65301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 65401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 65501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 65601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 65701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 65801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 65901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 66001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 66101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 66201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 66301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 66401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 66501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 66601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 66701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 66801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 66901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 67001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 67101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 67201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 67301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 67401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 67501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 67601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 67701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 67801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 67901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 68001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 68101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 68201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 68301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 68401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 68501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 68601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 68701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 68801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 68901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 69001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 69101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 69201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 69301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 69401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 69501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 69601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 69701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 69801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 69901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 70001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 70101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 70201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 70301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 70401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 70501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 70601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 70701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 70801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 70901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 71001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 71101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 71201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 71301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 71401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 71501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 71601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 71701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 71801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 71901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 72001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 72101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 72201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 72301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 72401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 72501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 72601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 72701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 72801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 72901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 73001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 73101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 73201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 73301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 73401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 73501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 73601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 73701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 73801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 73901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 74001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 74101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 74201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 74301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 74401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 74501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 74601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 74701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 74801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 74901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 75001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 75101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 75201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 75301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 75401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 75501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 75601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 75701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 75801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 75901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 76001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 76101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 76201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 76301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 76401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 76501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 76601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 76701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 76801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 76901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 77001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 77101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 77201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 77301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 77401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 77501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 77601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 77701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 77801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 77901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 78001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 78101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 78201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 78301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 78401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 78501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 78601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 78701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 78801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 78901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 79001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 79101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 79201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 79301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 79401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 79501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 79601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 79701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 79801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 79901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 80001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 80101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 80201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 80301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 80401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 80501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 80601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 80701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 80801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 80901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 81001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 81101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 81201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 81301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 81401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 81501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 81601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 81701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 81801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 81901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 82001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 82101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 82201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 82301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 82401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 82501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 82601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 82701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 82801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 82901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 83001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 83101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 83201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 83301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 83401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 83501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 83601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 83701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 83801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 83901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 84001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 84101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 84201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 84301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 84401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 84501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 84601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 84701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 84801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 84901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 85001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 85101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 85201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 85301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 85401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 85501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 85601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 85701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 85801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 85901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 86001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 86101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 86201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 86301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 86401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 86501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 86601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 86701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 86801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 86901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 87001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 87101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 87201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 87301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 87401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 87501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 87601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 87701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 87801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 87901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 88001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 88101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 88201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 88301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 88401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 88501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 88601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 88701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 88801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 88901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 89001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 89101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 89201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 89301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 89401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 89501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 89601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 89701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 89801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 89901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 90001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 90101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 90201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 90301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 90401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 90501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 90601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 90701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 90801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 90901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 91001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 91101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 91201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 91301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 91401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 91501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 91601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 91701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 91801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 91901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 92001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 92101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 92201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 92301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 92401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 92501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 92601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 92701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 92801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 92901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 93001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 93101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 93201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 93301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 93401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 93501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 93601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 93701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 93801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 93901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 94001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 94101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 94201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 94301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 94401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 94501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 94601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 94701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 94801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 94901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 95001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 95101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 95201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 95301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 95401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 95501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 95601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 95701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 95801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 95901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 96001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 96101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 96201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 96301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 96401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 96501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 96601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 96701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 96801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 96901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 97001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 97101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 97201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 97301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 97401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 97501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 97601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 97701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 97801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 97901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 98001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 98101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 98201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 98301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 98401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 98501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 98601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 98701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 98801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 98901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 99001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 99101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 99201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 99301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 99401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 99501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 99601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 99701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 99801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 99901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 100001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 100101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 100201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 100301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 100401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 100501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 100601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 100701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 100801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 100901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 101901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 102001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 102101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 102201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 102301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 102401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 102501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 102601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 102701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 102801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 102901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 103001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 103101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 103201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 103301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 103401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 103501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 103601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 103701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 103801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 103901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 104001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 104101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 104201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 104301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 104401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 104501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 104601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 104701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 104801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 104901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 105001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 105101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 105201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 105301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 105401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 105501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 105601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 105701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 105801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 105901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 106001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 106101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 106201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 106301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 106401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 106501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 106601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 106701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 106801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 106901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 107001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 107101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 107201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 107301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 107401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 107501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 107601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 107701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 107801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 107901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 108001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 108101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 108201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 108301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 108401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 108501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 108601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 108701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 108801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 108901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 109001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 109101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 109201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 109301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 109401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 109501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 109601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 109701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 109801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 109901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 110001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 110101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 110201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 110301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 110401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 110501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 110601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 110701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 110801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 110901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 111001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 111101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 111201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 111301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 111401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 111501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 111601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 111701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 111801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 111901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 112001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 112101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 112201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 112301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 112401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 112501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 112601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 112701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 112801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 112901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 113001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 113101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 113201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 113301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 113401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 113501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 113601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 113701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 113801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 113901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 114001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 114101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 114201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 114301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 114401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 114501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 114601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 114701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 114801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 114901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 115001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 115101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 115201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 115301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 115401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 115501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 115601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 115701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 115801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 115901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 116001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 116101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 116201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 116301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 116401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 116501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 116601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 116701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 116801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 116901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 117001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 117101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 117201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 117301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 117401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 117501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 117601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 117701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 117801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 117901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 118001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 118101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 118201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 118301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 118401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 118501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 118601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 118701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 118801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 118901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 119001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 119101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 119201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 119301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 119401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 119501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 119601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 119701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 119801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 119901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 120001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 120101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 120201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 120301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 120401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 120501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 120601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 120701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 120801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 120901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 121001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 121101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 121201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 121301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 121401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 121501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 121601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 121701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 121801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 121901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 122001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 122101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 122201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 122301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 122401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 122501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 122601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 122701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 122801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 122901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 123001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 123101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 123201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 123301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 123401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 123501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 123601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 123701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 123801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 123901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 124001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 124101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 124201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 124301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 124401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 124501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 124601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 124701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 124801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 124901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 125001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 125101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 125201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 125301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 125401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 125501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 125601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 125701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 125801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 125901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 126001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 126101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 126201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 126301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 126401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 126501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 126601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 126701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 126801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 126901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 127001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 127101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 127201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 127301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 127401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 127501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 127601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 127701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 127801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 127901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 128001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 128101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 128201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 128301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 128401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 128501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 128601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 128701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 128801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 128901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 129001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 129101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 129201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 129301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 129401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 129501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 129601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 129701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 129801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 129901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 130001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 130101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 130201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 130301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 130401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 130501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 130601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 130701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 130801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 130901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 131001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 131101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 131201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 131301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 131401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 131501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 131601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 131701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 131801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 131901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 132001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 132101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 132201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 132301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 132401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 132501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 132601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 132701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 132801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 132901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 133001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 133101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 133201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 133301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 133401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 133501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 133601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 133701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 133801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 133901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 134001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 134101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 134201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 134301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 134401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 134501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 134601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 134701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 134801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 134901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 135001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 135101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 135201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 135301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 135401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 135501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 135601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 135701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 135801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 135901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 136001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 136101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 136201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 136301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 136401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 136501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 136601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 136701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 136801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 136901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 137001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 137101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 137201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 137301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 137401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 137501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 137601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 137701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 137801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 137901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 138001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 138101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 138201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 138301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 138401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 138501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 138601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 138701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 138801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 138901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 139001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 139101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 139201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 139301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 139401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 139501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 139601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 139701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 139801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 139901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 140001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 140101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 140201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 140301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 140401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 140501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 140601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 140701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 140801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 140901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 141001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 141101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 141201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 141301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 141401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 141501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 141601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 141701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 141801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 141901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 142001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 142101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 142201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 142301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 142401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 142501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 142601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 142701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 142801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 142901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 143001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 143101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 143201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 143301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 143401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 143501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 143601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 143701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 143801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 143901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 144001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 144101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 144201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 144301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 144401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 144501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 144601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 144701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 144801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 144901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 145001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 145101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 145201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 145301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 145401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 145501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 145601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 145701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 145801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 145901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 146001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 146101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 146201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 146301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 146401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 146501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 146601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 146701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 146801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 146901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 147001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 147101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 147201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 147301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 147401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 147501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 147601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 147701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 147801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 147901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 148001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 148101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 148201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 148301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 148401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 148501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 148601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 148701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 148801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 148901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 149001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 149101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 149201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 149301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 149401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 149501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 149601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 149701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 149801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 149901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 150001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 150101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 150201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 150301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 150401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 150501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 150601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 150701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 150801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 150901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 151001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 151101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 151201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 151301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 151401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 151501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 151601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 151701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 151801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 151901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 152001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 152101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 152201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 152301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 152401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 152501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 152601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 152701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 152801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 152901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 153001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 153101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 153201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 153301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 153401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 153501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 153601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 153701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 153801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 153901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 154001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 154101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 154201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 154301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 154401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 154501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 154601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 154701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 154801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 154901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 155001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 155101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 155201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 155301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 155401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 155501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 155601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 155701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 155801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 155901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 156001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 156101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 156201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 156301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 156401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 156501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 156601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 156701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 156801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 156901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 157001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 157101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 157201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 157301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 157401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 157501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 157601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 157701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 157801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 157901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 158001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 158101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 158201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 158301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 158401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 158501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 158601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 158701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 158801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 158901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 159001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 159101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 159201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 159301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 159401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 159501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 159601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 159701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 159801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 159901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 160001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 160101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 160201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 160301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 160401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 160501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 160601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 160701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 160801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 160901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 161001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 161101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 161201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 161301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 161401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 161501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 161601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 161701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 161801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 161901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 162001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 162101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 162201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 162301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 162401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 162501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 162601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 162701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 162801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 162901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 163001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 163101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 163201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 163301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 163401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 163501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 163601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 163701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 163801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 163901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 164001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 164101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 164201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 164301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 164401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 164501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 164601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 164701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 164801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 164901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 165001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 165101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 165201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 165301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 165401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 165501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 165601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 165701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 165801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 165901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 166001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 166101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 166201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 166301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 166401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 166501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 166601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 166701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 166801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 166901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 167001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 167101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 167201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 167301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 167401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 167501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 167601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 167701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 167801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 167901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 168001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 168101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 168201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 168301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 168401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 168501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 168601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 168701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 168801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 168901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 169001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 169101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 169201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 169301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 169401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 169501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 169601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 169701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 169801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 169901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 170001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 170101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 170201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 170301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 170401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 170501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 170601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 170701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 170801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 170901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 171001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 171101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 171201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 171301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 171401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 171501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 171601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 171701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 171801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 171901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 172001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 172101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 172201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 172301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 172401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 172501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 172601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 172701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 172801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 172901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 173001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 173101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 173201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 173301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 173401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 173501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 173601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 173701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 173801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 173901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 174001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 174101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 174201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 174301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 174401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 174501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 174601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 174701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 174801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 174901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 175001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 175101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 175201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 175301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 175401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 175501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 175601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 175701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 175801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 175901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 176001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 176101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 176201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 176301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 176401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 176501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 176601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 176701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 176801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 176901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 177001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 177101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 177201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 177301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 177401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 177501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 177601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 177701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 177801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 177901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 178001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 178101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 178201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 178301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 178401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 178501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 178601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 178701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 178801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 178901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 179001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 179101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 179201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 179301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 179401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 179501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 179601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 179701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 179801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 179901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 180001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 180101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 180201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 180301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 180401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 180501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 180601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 180701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 180801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 180901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 181001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 181101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 181201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 181301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 181401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 181501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 181601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 181701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 181801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 181901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 182001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 182101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 182201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 182301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 182401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 182501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 182601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 182701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 182801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 182901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 183001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 183101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 183201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 183301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 183401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 183501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 183601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 183701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 183801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 183901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 184001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 184101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 184201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 184301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 184401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 184501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 184601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 184701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 184801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 184901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 185001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 185101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 185201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 185301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 185401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 185501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 185601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 185701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 185801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 185901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 186001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 186101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 186201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 186301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 186401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 186501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 186601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 186701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 186801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 186901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 187001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 187101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 187201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 187301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 187401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 187501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 187601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 187701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 187801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 187901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 188001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 188101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 188201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 188301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 188401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 188501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 188601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 188701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 188801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 188901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 189001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 189101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 189201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 189301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 189401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 189501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 189601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 189701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 189801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 189901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 190001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 190101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 190201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 190301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 190401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 190501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 190601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 190701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 190801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 190901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 191001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 191101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 191201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 191301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 191401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 191501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 191601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 191701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 191801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 191901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 192001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 192101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 192201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 192301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 192401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 192501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 192601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 192701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 192801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 192901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 193001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 193101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 193201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 193301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 193401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 193501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 193601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 193701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 193801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 193901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 194001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 194101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 194201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 194301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 194401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 194501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 194601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 194701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 194801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 194901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 195001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 195101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 195201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 195301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 195401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 195501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 195601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 195701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 195801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 195901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 196001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 196101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 196201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 196301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 196401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 196501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 196601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 196701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 196801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 196901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 197001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 197101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 197201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 197301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 197401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 197501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 197601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 197701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 197801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 197901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 198001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 198101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 198201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 198301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 198401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 198501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 198601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 198701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 198801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 198901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 199001\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 199101\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 199201\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 199301\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 199401\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 199501\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 199601\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 199701\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 199801\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n",
      "Step 199901\n",
      "Action:  [0]\n",
      "obs= [[0. 0. 0. 0.]] reward= [0.] done= [False]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "states = np.array(states)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharex=True)  # , sharex=True, sharey=True)\n",
    "fig.suptitle(\"average speed: {:.3}\".format( states[-1, 0] / ts[-1]))\n",
    "axs[0, 0].plot(ts, states[:, 0], label=\"x\")\n",
    "axs[0, 0].set_title(\"x\")\n",
    "axs[1, 0].plot(ts, states[:, 1], label=\"dx\")\n",
    "axs[1, 0].set_title(\"dx\")\n",
    "axs[0, 1].plot(ts, states[:, 2] + states[:, 0], label=\"xi\")\n",
    "axs[1, 0].set_title(\"xi\")\n",
    "axs[1, 1].plot(ts, states[:, 3], label=\"dxi\")\n",
    "axs[1, 1].set_title(\"dxi\")\n",
    "t_shift = 3\n",
    "axs[0, 0].set_xlim(t_shift, t_shift + 1)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, actions, label=\"F\")\n",
    "plt.xlim(t_shift, t_shift + 1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/xfirefly/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:134: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}